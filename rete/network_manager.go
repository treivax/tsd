// Copyright (c) 2025 TSD Contributors
// Licensed under the MIT License
// See LICENSE file in the project root for full license text

package rete

import (
	"fmt"
	"sync"
	"time"
)

// Protection contre les boucles infinies dans les Update en cha√Æne
const maxUpdateDepth = 100

var (
	updateDepthMutex sync.Mutex
	updateDepthCount int
)

// SubmitFact soumet un nouveau fait au r√©seau RETE
// Si une transaction est active, la commande est enregistr√©e pour rollback
func (rn *ReteNetwork) SubmitFact(fact *Fact) error {
	rn.logger.Debug("üî• Soumission fait: %s", fact.String())

	// Debug logging for E2E debugging
	debugLogger := GetDebugLogger()
	debugLogger.LogFactSubmission(fact.Type, fact.ID, fact.Fields)

	// V√©rifier si une transaction est active
	tx := rn.GetTransaction()
	if tx != nil && tx.IsActive {
		// Mode transactionnel : enregistrer la commande
		cmd := NewAddFactCommand(rn.Storage, fact)
		if err := tx.RecordAndExecute(cmd); err != nil {
			return err
		}
		// Propager le fait dans le r√©seau
		return rn.RootNode.ActivateRight(fact)
	}

	// Mode normal : ex√©cution directe
	if err := rn.Storage.AddFact(fact); err != nil {
		return err
	}
	return rn.RootNode.ActivateRight(fact)
}

// RemoveFact supprime un fait du r√©seau
// Si une transaction est active, la commande est enregistr√©e pour rollback
func (rn *ReteNetwork) RemoveFact(factID string) error {
	tx := rn.GetTransaction()
	if tx != nil && tx.IsActive {
		cmd := NewRemoveFactCommand(rn.Storage, factID)
		return tx.RecordAndExecute(cmd)
	}

	return rn.Storage.RemoveFact(factID)
}

// InsertFact ins√®re dynamiquement un nouveau fait dans le r√©seau RETE.
// Cette m√©thode valide le fait, l'ajoute au storage et le propage dans le r√©seau.
//
// Param√®tres:
//   - fact: le fait √† ins√©rer
//
// Retourne:
//   - error: erreur si le fait est invalide ou s'il existe d√©j√†
func (rn *ReteNetwork) InsertFact(fact *Fact) error {
	// Validation du fait
	if fact == nil {
		return fmt.Errorf("fact cannot be nil")
	}
	if fact.Type == "" {
		return fmt.Errorf("fact type cannot be empty")
	}
	if fact.ID == "" {
		return fmt.Errorf("fact ID cannot be empty")
	}

	// V√©rifier si le fait existe d√©j√†
	internalID := fact.GetInternalID()
	if existingFact := rn.Storage.GetFact(internalID); existingFact != nil {
		return fmt.Errorf("fact with ID '%s' and type '%s' already exists", fact.ID, fact.Type)
	}

	// Utiliser SubmitFact qui g√®re d√©j√† le storage et la propagation
	return rn.SubmitFact(fact)
}

// UpdateFact met √† jour dynamiquement un fait existant dans le r√©seau RETE.
// Cette m√©thode remplace les champs du fait existant et propage les changements.
//
// Param√®tres:
//   - fact: le fait avec les nouvelles valeurs
//
// Retourne:
//   - error: erreur si le fait est invalide ou n'existe pas
func (rn *ReteNetwork) UpdateFact(fact *Fact) error {
	// Validation du fait
	if fact == nil {
		return fmt.Errorf("fact cannot be nil")
	}
	if fact.Type == "" {
		return fmt.Errorf("fact type cannot be empty")
	}
	if fact.ID == "" {
		return fmt.Errorf("fact ID cannot be empty")
	}

	// V√©rifier que le fait existe
	internalID := fact.GetInternalID()
	existingFact := rn.Storage.GetFact(internalID)
	if existingFact == nil {
		return fmt.Errorf("fact with ID '%s' and type '%s' not found", fact.ID, fact.Type)
	}

	// V√©rifier si le fait a r√©ellement chang√©
	// Si toutes les valeurs sont identiques, ne rien faire pour √©viter les boucles infinies
	if areFactsEqual(existingFact, fact) {
		rn.logger.Debug("üîÑ Update ignor√©: le fait %s n'a pas chang√©", internalID)
		return nil
	}

	// Protection contre les boucles infinies (r√®gles qui se d√©clenchent en cha√Æne)
	updateDepthMutex.Lock()
	updateDepthCount++
	currentDepth := updateDepthCount
	updateDepthMutex.Unlock()

	defer func() {
		updateDepthMutex.Lock()
		updateDepthCount--
		updateDepthMutex.Unlock()
	}()

	if currentDepth > maxUpdateDepth {
		return fmt.Errorf("maximum update depth exceeded (%d) - possible infinite loop in chained rules", maxUpdateDepth)
	}

	rn.logger.Debug("üîÑ Mise √† jour du fait: %s (depth: %d)", internalID, currentDepth)

	// Strat√©gie: Retract puis Insert pour garantir la coh√©rence
	// Cela propage correctement la suppression puis l'ajout dans le r√©seau

	// 1. R√©tracter l'ancien fait (propage la suppression)
	if err := rn.RetractFact(internalID); err != nil {
		return fmt.Errorf("failed to retract old fact: %w", err)
	}

	// 2. Ins√©rer le nouveau fait avec les valeurs mises √† jour (propage l'ajout)
	if err := rn.SubmitFact(fact); err != nil {
		return fmt.Errorf("failed to submit updated fact: %w", err)
	}

	return nil
}

// areFactsEqual compare deux faits pour v√©rifier s'ils ont les m√™mes valeurs
// Retourne true si tous les champs ont des valeurs identiques
func areFactsEqual(a, b *Fact) bool {
	if a == nil || b == nil {
		return false
	}

	if a.Type != b.Type || a.ID != b.ID {
		return false
	}

	// V√©rifier que les deux faits ont le m√™me nombre de champs
	if len(a.Fields) != len(b.Fields) {
		return false
	}

	// Comparer chaque champ
	for key, aValue := range a.Fields {
		bValue, exists := b.Fields[key]
		if !exists {
			return false
		}

		// Comparaison des valeurs avec gestion des types num√©riques
		if !areValuesEqualForFacts(aValue, bValue) {
			return false
		}
	}

	return true
}

// areValuesEqualForFacts compare deux valeurs de champs de faits
// G√®re les conversions de types num√©riques (int, int64, float64)
func areValuesEqualForFacts(a, b interface{}) bool {
	if a == nil && b == nil {
		return true
	}
	if a == nil || b == nil {
		return false
	}

	// Comparaison directe pour les types identiques
	if a == b {
		return true
	}

	// Comparaison sp√©ciale pour les nombres (int, int64, float64)
	aNum, aIsNum := toFloat64ForFacts(a)
	bNum, bIsNum := toFloat64ForFacts(b)
	if aIsNum && bIsNum {
		return aNum == bNum
	}

	return false
}

// toFloat64ForFacts convertit un nombre en float64 si possible
func toFloat64ForFacts(v interface{}) (float64, bool) {
	switch val := v.(type) {
	case float64:
		return val, true
	case int:
		return float64(val), true
	case int64:
		return float64(val), true
	default:
		return 0, false
	}
}

// RepropagateExistingFact propage un fait d√©j√† existant dans le r√©seau vers les nouveaux n≈ìuds
// Cette fonction est utilis√©e en mode incr√©mental pour propager les faits existants
// vers les nouvelles r√®gles qui viennent d'√™tre ajout√©es au r√©seau
func (rn *ReteNetwork) RepropagateExistingFact(fact *Fact) error {
	// Ne pas ajouter le fait au RootNode ou TypeNode (il y est d√©j√†)
	// Propager directement aux enfants du TypeNode (AlphaNodes, etc.)
	typeNode, exists := rn.TypeNodes[fact.Type]
	if !exists {
		return fmt.Errorf("type %s non trouv√© dans le r√©seau", fact.Type)
	}

	// Cr√©er un token pour ce fait
	token := &Token{
		ID:     fmt.Sprintf("token_%s_%s", fact.Type, fact.ID),
		NodeID: typeNode.GetID(),
		Facts:  []*Fact{fact},
	}

	// Propager directement aux enfants du TypeNode sans ajouter √† sa m√©moire
	return typeNode.PropagateToChildren(fact, token)
}

// waitForFactPersistence attend qu'un fait soit persist√© avec retry + backoff exponentiel
// Cette fonction impl√©mente la barri√®re de synchronisation de la Phase 2
func (rn *ReteNetwork) waitForFactPersistence(fact *Fact, timeout time.Duration) error {
	return rn.waitForFactPersistenceWithMetrics(fact, timeout, nil)
}

// waitForFactPersistenceWithMetrics attend la persistance d'un fait avec collecte de m√©triques optionnelle
func (rn *ReteNetwork) waitForFactPersistenceWithMetrics(fact *Fact, timeout time.Duration, metricsCollector *CoherenceMetricsCollector) error {
	internalID := fact.GetInternalID()
	deadline := time.Now().Add(timeout)
	attempt := 0

	for time.Now().Before(deadline) {
		attempt++

		// Enregistrer la tentative de v√©rification
		if metricsCollector != nil {
			metricsCollector.RecordVerifyAttempt()
		}

		// V√©rifier si le fait est persist√©
		if storedFact := rn.Storage.GetFact(internalID); storedFact != nil {
			// ‚úÖ Fait trouv√©
			if attempt > 1 {
				rn.logger.Info("‚úÖ Fait %s persist√© apr√®s %d tentative(s)", fact.ID, attempt)
				if metricsCollector != nil {
					metricsCollector.RecordFactRetried()
					metricsCollector.RecordRetry(attempt - 1)
				}
			}
			return nil
		}

		// Si on n'a pas d√©pass√© le nombre max de retries, utiliser backoff exponentiel
		if attempt < rn.MaxVerifyRetries {
			// Backoff exponentiel: 10ms, 20ms, 40ms, 80ms, 160ms, 320ms, max 500ms
			backoff := rn.VerifyRetryDelay * time.Duration(1<<uint(attempt-1))
			if backoff > 500*time.Millisecond {
				backoff = 500 * time.Millisecond
			}
			time.Sleep(backoff)
		} else {
			// Apr√®s max retries, attendre un peu avant de v√©rifier √† nouveau
			time.Sleep(100 * time.Millisecond)
		}
	}

	// ‚ùå Timeout d√©pass√©
	return fmt.Errorf("timeout: fait %s (ID interne: %s) non persist√© apr√®s %v",
		fact.ID, internalID, timeout)
}

// SubmitFactsFromGrammar soumet une liste de faits au r√©seau RETE avec garanties de synchronisation (Phase 2)
// Cette fonction garantit que tous les faits soumis sont persist√©s et visibles avant de retourner
func (rn *ReteNetwork) SubmitFactsFromGrammar(facts []map[string]interface{}) error {
	return rn.submitFactsFromGrammarWithMetrics(facts, nil)
}

// SubmitFactsFromGrammarWithMetrics soumet des faits avec collecte de m√©triques de coh√©rence
func (rn *ReteNetwork) SubmitFactsFromGrammarWithMetrics(facts []map[string]interface{}, metricsCollector *CoherenceMetricsCollector) error {
	return rn.submitFactsFromGrammarWithMetrics(facts, metricsCollector)
}

// submitFactsFromGrammarWithMetrics est l'impl√©mentation interne avec support optionnel des m√©triques
func (rn *ReteNetwork) submitFactsFromGrammarWithMetrics(facts []map[string]interface{}, metricsCollector *CoherenceMetricsCollector) error {
	if len(facts) == 0 {
		return nil
	}

	// Debug: dump network structure before fact submission
	debugLogger := GetDebugLogger()
	if debugLogger.IsEnabled() {
		debugLogger.LogNetworkStructure(rn)
	}

	// Cr√©er un contexte de soumission pour tracker les r√©tractations
	ctx := NewSubmissionContext()
	rn.submissionMutex.Lock()
	rn.currentSubmission = ctx
	rn.submissionMutex.Unlock()
	// Note: currentSubmission n'est PAS nettoy√© ici pour permettre au pipeline
	// de v√©rifier les r√©tractations apr√®s la soumission.
	// Il sera nettoy√© manuellement apr√®s utilisation.

	// D√©marrer la phase de soumission si collecteur disponible
	if metricsCollector != nil {
		metricsCollector.StartPhase("fact_submission")
		defer func() {
			metricsCollector.EndPhase("fact_submission", len(facts), true)
		}()
	}

	// Timeout par fait : timeout total divis√© par nombre de faits
	// Minimum 1 seconde par fait pour √©viter les timeouts pr√©matur√©s
	timeoutPerFact := rn.SubmissionTimeout / time.Duration(len(facts))
	if timeoutPerFact < 1*time.Second {
		timeoutPerFact = 1 * time.Second
	}

	// Compteurs pour garantir la coh√©rence
	factsSubmitted := 0
	factsPersisted := 0
	factsRetractedDuringSubmission := 0
	startTime := time.Now()

	for i, factMap := range facts {
		// 1. Convertir le map en Fact
		var factID string
		var factType string

		// Utiliser _id_ qui contient l'ID interne complet (Type~Value)
		if id, ok := factMap["_id_"].(string); ok {
			factID = id
		} else {
			// Fallback: construire l'ID interne si _id_ n'existe pas
			rawID := fmt.Sprintf("fact_%d", i)
			if id, ok := factMap["id"].(string); ok {
				rawID = id
			}

			factType = "unknown"
			// Chercher "type" ou "reteType" (ConvertFactsToReteFormat utilise "reteType")
			if typ, ok := factMap["type"].(string); ok {
				factType = typ
			} else if typ, ok := factMap["reteType"].(string); ok {
				factType = typ
			}

			// Construire l'ID interne complet au format Type~Value
			factID = fmt.Sprintf("%s~%s", factType, rawID)
		}

		// Si factType n'a pas √©t√© d√©fini ci-dessus, le r√©cup√©rer maintenant
		if factType == "" {
			factType = "unknown"
			if typ, ok := factMap["type"].(string); ok {
				factType = typ
			} else if typ, ok := factMap["reteType"].(string); ok {
				factType = typ
			}
		}

		fact := &Fact{
			ID:     factID,
			Type:   factType,
			Fields: make(map[string]interface{}),
		}

		// Copier tous les champs
		for key, value := range factMap {
			if key != "type" && key != "reteType" {
				fact.Fields[key] = value
			}
		}

		// 2. Marquer le fait comme soumis dans le contexte
		ctx.MarkSubmitted(fact.ID)

		// 3. Soumettre le fait au r√©seau RETE
		if metricsCollector != nil {
			metricsCollector.RecordFactSubmitted()
		}

		if err := rn.SubmitFact(fact); err != nil {
			if metricsCollector != nil {
				metricsCollector.RecordFactFailed()
			}
			return fmt.Errorf("erreur soumission fait %s: %w", fact.ID, err)
		}
		factsSubmitted++

		// 4. Barri√®re de synchronisation Phase 2 : attendre la persistance avec retry
		// SAUF si le fait a √©t√© r√©tract√© pendant la propagation (comportement valide)
		if ctx.WasRetracted(fact.ID) {
			// Fait r√©tract√© pendant la propagation : OK, ne pas v√©rifier
			rn.logger.Info("‚ÑπÔ∏è  Fait %s r√©tract√© pendant la propagation, v√©rification Phase 2 ignor√©e", fact.ID)
			factsRetractedDuringSubmission++
			if metricsCollector != nil {
				// Le fait a √©t√© "persist√©" puis imm√©diatement r√©tract√©, c'est une op√©ration r√©ussie
				metricsCollector.RecordFactPersisted()
			}
		} else {
			// Fait non r√©tract√© : attendre la persistance
			waitStart := time.Now()
			err := rn.waitForFactPersistenceWithMetrics(fact, timeoutPerFact, metricsCollector)
			waitDuration := time.Since(waitStart)

			if metricsCollector != nil {
				metricsCollector.RecordWaitTime(waitDuration)
			}

			if err != nil {
				if metricsCollector != nil {
					metricsCollector.RecordTimeout()
					metricsCollector.RecordFactFailed()
				}
				return fmt.Errorf("√©chec synchronisation fait %s: %w", fact.ID, err)
			}

			if metricsCollector != nil {
				metricsCollector.RecordFactPersisted()
			}
			factsPersisted++
		}
	}

	duration := time.Since(startTime)

	if metricsCollector != nil {
		metricsCollector.RecordSubmissionTime(duration)
	}

	// 5. V√©rification finale de coh√©rence
	// Les faits r√©tract√©s pendant la propagation sont compt√©s comme trait√©s avec succ√®s
	totalProcessed := factsPersisted + factsRetractedDuringSubmission
	if factsSubmitted != totalProcessed {
		return fmt.Errorf("incoh√©rence d√©tect√©e: %d faits soumis mais seulement %d trait√©s (%d persist√©s, %d r√©tract√©s)",
			factsSubmitted, totalProcessed, factsPersisted, factsRetractedDuringSubmission)
	}

	if factsRetractedDuringSubmission > 0 {
		rn.logger.Info("‚úÖ Phase 2 - Synchronisation compl√®te: %d/%d faits trait√©s (%d persist√©s, %d r√©tract√©s) en %v",
			totalProcessed, factsSubmitted, factsPersisted, factsRetractedDuringSubmission, duration)
	} else {
		rn.logger.Info("‚úÖ Phase 2 - Synchronisation compl√®te: %d/%d faits persist√©s en %v", factsPersisted, factsSubmitted, duration)
	}

	return nil
}

// ClearSubmissionContext nettoie le contexte de soumission actuel.
// Cette fonction doit √™tre appel√©e apr√®s avoir v√©rifi√© les r√©tractations
// dans le pipeline, pour lib√©rer la m√©moire.
func (rn *ReteNetwork) ClearSubmissionContext() {
	rn.submissionMutex.Lock()
	rn.currentSubmission = nil
	rn.submissionMutex.Unlock()
}

// RetractFact supprime dynamiquement un fait du r√©seau RETE.
// Cette m√©thode retire le fait du storage et propage la suppression.
//
// Param√®tres:
//   - factID: l'identifiant interne du fait (format: Type_ID)
//
// Retourne:
//   - error: erreur si l'ID est vide ou si le fait n'existe pas
func (rn *ReteNetwork) RetractFact(factID string) error {
	// Validation de l'ID
	if factID == "" {
		return fmt.Errorf("fact ID cannot be empty")
	}

	rn.logger.Info("üóëÔ∏è R√©tractation du fait: %s", factID)

	// V√©rifier que le fait existe
	existingFact := rn.Storage.GetFact(factID)
	if existingFact == nil {
		return fmt.Errorf("fact with ID '%s' not found", factID)
	}

	// Marquer le fait comme r√©tract√© dans le contexte de soumission s'il y en a un actif
	rn.submissionMutex.RLock()
	if rn.currentSubmission != nil && rn.currentSubmission.WasSubmitted(factID) {
		rn.currentSubmission.MarkRetracted(factID)
		rn.logger.Debug("üîÑ Fait %s marqu√© comme r√©tract√© dans le contexte de soumission actif", factID)
	}
	rn.submissionMutex.RUnlock()

	// Utiliser RemoveFact qui g√®re le storage et les transactions
	if err := rn.RemoveFact(factID); err != nil {
		return fmt.Errorf("failed to remove fact from storage: %w", err)
	}

	// Propager la r√©tractation dans le r√©seau
	return rn.RootNode.ActivateRetract(factID)
}

// Reset clears the entire RETE network and resets it to an empty state.
// This removes all facts, rules, types, and network nodes.
// After calling Reset, the network is ready to accept new definitions from scratch.
func (rn *ReteNetwork) Reset() {
	rn.logger.Info("üßπ R√©initialisation compl√®te du r√©seau RETE")

	// Clear all node collections
	rn.TypeNodes = make(map[string]*TypeNode)
	rn.AlphaNodes = make(map[string]*AlphaNode)
	rn.BetaNodes = make(map[string]interface{})
	rn.TerminalNodes = make(map[string]*TerminalNode)
	rn.Types = make([]TypeDefinition, 0)
	rn.BetaBuilder = nil

	// Reset lifecycle manager (always initialized)
	rn.LifecycleManager.Reset()

	// Reset alpha sharing manager (always initialized)
	rn.AlphaSharingManager.Reset()

	// Reset passthrough registry
	rn.PassthroughRegistry = make(map[string]*AlphaNode)

	// Recreate a fresh root node with the existing storage
	rn.RootNode = NewRootNode(rn.Storage)

	rn.logger.Info("‚úÖ R√©seau RETE r√©initialis√© avec succ√®s")
}

// ClearMemory efface uniquement les m√©moires (faits et tokens) de tous les n≈ìuds
// sans d√©truire la structure du r√©seau
func (rn *ReteNetwork) ClearMemory() {
	rn.logger.Info("üßπ Nettoyage de la m√©moire du r√©seau RETE")

	// Clear TypeNode memories
	for _, typeNode := range rn.TypeNodes {
		typeNode.mutex.Lock()
		typeNode.Memory.Facts = make(map[string]*Fact)
		typeNode.Memory.Tokens = make(map[string]*Token)
		typeNode.mutex.Unlock()
	}

	// Clear AlphaNode memories
	for _, alphaNode := range rn.AlphaNodes {
		alphaNode.mutex.Lock()
		alphaNode.Memory.Facts = make(map[string]*Fact)
		alphaNode.Memory.Tokens = make(map[string]*Token)
		alphaNode.mutex.Unlock()
	}

	// Clear BetaNode memories (JoinNodes, etc.)
	for _, betaNode := range rn.BetaNodes {
		if node, ok := betaNode.(Node); ok {
			node.GetMemory().Facts = make(map[string]*Fact)
			node.GetMemory().Tokens = make(map[string]*Token)
		}
	}

	// Clear TerminalNode memories
	for _, terminalNode := range rn.TerminalNodes {
		terminalNode.mutex.Lock()
		terminalNode.Memory.Facts = make(map[string]*Fact)
		terminalNode.Memory.Tokens = make(map[string]*Token)
		terminalNode.mutex.Unlock()
	}

	rn.logger.Info("‚úÖ M√©moire du r√©seau RETE nettoy√©e avec succ√®s")
}

// GarbageCollect nettoie et lib√®re les ressources du r√©seau
func (rn *ReteNetwork) GarbageCollect() {
	// 1. Vider les caches
	if rn.ArithmeticResultCache != nil {
		rn.ArithmeticResultCache.Clear()
	}

	// BetaSharingRegistry and AlphaSharingManager are always initialized
	rn.BetaSharingRegistry.Clear()
	rn.AlphaSharingManager.Clear()

	// 2. Nettoyer les n≈ìuds et supprimer les r√©f√©rences
	// TypeNodes
	for _, node := range rn.TypeNodes {
		if node != nil && node.Memory != nil {
			node.Memory.Facts = make(map[string]*Fact)
			node.Memory.Tokens = make(map[string]*Token)
		}
		if node != nil {
			node.Children = nil
		}
	}
	rn.TypeNodes = make(map[string]*TypeNode)

	// AlphaNodes
	for _, node := range rn.AlphaNodes {
		if node != nil && node.Memory != nil {
			node.Memory.Facts = make(map[string]*Fact)
			node.Memory.Tokens = make(map[string]*Token)
		}
		if node != nil {
			node.Children = nil
		}
	}
	rn.AlphaNodes = make(map[string]*AlphaNode)

	// BetaNodes
	rn.BetaNodes = make(map[string]interface{})

	// TerminalNodes
	for _, node := range rn.TerminalNodes {
		if node != nil && node.Memory != nil {
			node.Memory.Facts = make(map[string]*Fact)
			node.Memory.Tokens = make(map[string]*Token)
		}
		if node != nil {
			node.Children = nil
		}
	}
	rn.TerminalNodes = make(map[string]*TerminalNode)

	// 3. Vider les types
	rn.Types = make([]TypeDefinition, 0)

	// 4. Vider le PassthroughRegistry
	rn.PassthroughRegistry = make(map[string]*AlphaNode)

	// 5. Nettoyer le LifecycleManager
	if rn.LifecycleManager != nil {
		rn.LifecycleManager.Cleanup()
	}

	// 6. Nettoyer l'ActionExecutor
	if rn.ActionExecutor != nil {
		// ActionExecutor n'a pas de m√©thode Cleanup pour l'instant
		// mais on pourrait en ajouter une si n√©cessaire
	}

	// 7. Nettoyer le Storage
	if rn.Storage != nil {
		rn.Storage.Clear()
	}

	// 8. R√©initialiser le RootNode
	if rn.RootNode != nil && rn.RootNode.Memory != nil {
		rn.RootNode.Memory.Facts = make(map[string]*Fact)
		rn.RootNode.Memory.Tokens = make(map[string]*Token)
	}
}
