// Copyright (c) 2025 TSD Contributors
// Licensed under the MIT License
// See LICENSE file in the project root for full license text

package rete

import (
	"fmt"
	"os"
	"time"

	"github.com/treivax/tsd/constraint"
)

// ConstraintPipeline impl√©mente le pipeline complet :
// fichier .constraint ‚Üí parseur PEG ‚Üí conversion AST ‚Üí r√©seau RETE
type ConstraintPipeline struct {
	logger                *Logger                                                     // Logger structur√© pour instrumentation
	onXupleSpacesDetected func(network *ReteNetwork, definitions []interface{}) error // Callback appel√© apr√®s d√©tection des xuple-spaces
}

// GetLogger retourne le logger, en l'initialisant si n√©cessaire
func (cp *ConstraintPipeline) GetLogger() *Logger {
	if cp.logger == nil {
		cp.logger = NewLogger(LogLevelInfo, os.Stdout)
	}
	return cp.logger
}

// NewConstraintPipeline cr√©e une nouvelle instance du pipeline
func NewConstraintPipeline() *ConstraintPipeline {
	return &ConstraintPipeline{
		logger: NewLogger(LogLevelInfo, os.Stdout), // Logger par d√©faut niveau Info
	}
}

// SetLogger configure le logger pour le pipeline
func (cp *ConstraintPipeline) SetLogger(logger *Logger) {
	if logger != nil {
		cp.logger = logger
	}
}

// SetOnXupleSpacesDetected configure le callback appel√© apr√®s d√©tection des xuple-spaces.
// Ce callback permet au package api de cr√©er les xuple-spaces avant la soumission des faits inline.
func (cp *ConstraintPipeline) SetOnXupleSpacesDetected(callback func(network *ReteNetwork, definitions []interface{}) error) {
	cp.onXupleSpacesDetected = callback
}

// IngestFile est la fonction unique et incr√©mentale pour √©tendre le r√©seau RETE.
// Elle peut √™tre appel√©e plusieurs fois avec des fichiers diff√©rents pour :
// - Parser le fichier (types, r√®gles, faits)
// - √âtendre le r√©seau RETE existant (ou cr√©er un nouveau r√©seau si network == nil)
// - Propager les faits pr√©existants vers les nouvelles r√®gles
// - Soumettre les nouveaux faits au r√©seau
//
// Cette fonction remplace toutes les anciennes variantes de pipeline.
// Le support de la commande 'reset' en milieu de fichier a √©t√© supprim√©.
//
// IMPORTANT: Cette fonction utilise TOUJOURS les transactions avec auto-commit/auto-rollback.
// En cas d'erreur, la transaction est automatiquement annul√©e (rollback).
// En cas de succ√®s, la transaction est automatiquement valid√©e (commit).
//
// Les m√©triques sont toujours collect√©es et retourn√©es (co√ªt n√©gligeable < 0.1%).
func (cp *ConstraintPipeline) IngestFile(filename string, network *ReteNetwork, storage Storage) (*ReteNetwork, *IngestionMetrics, error) {
	cp.logger.Info("========================================")
	cp.logger.Info("üìÅ Ingestion incr√©mentale: %s", filename)

	// Initialiser le contexte d'ingestion
	ctx := &ingestionContext{
		filename:              filename,
		network:               network,
		storage:               storage,
		metrics:               NewMetricsCollector(),
		xupleManager:          nil, // Sera cr√©√© si n√©cessaire lors de la d√©tection de xuple-spaces
		onXupleSpacesDetected: cp.onXupleSpacesDetected,
	}

	// Ex√©cuter le pipeline complet
	if err := cp.executePipeline(ctx); err != nil {
		return cp.handlePipelineError(ctx, err)
	}

	cp.logger.Info("üéØ INGESTION TERMIN√âE")
	cp.logger.Info("========================================")

	return ctx.network, ctx.metrics.Finalize(), nil
}

// enrichProgramWithNetworkTypes merges types from the network into the program
// This is crucial for incremental validation when facts reference types defined in previous files
func (cp *ConstraintPipeline) enrichProgramWithNetworkTypes(program *constraint.Program, network *ReteNetwork) constraint.Program {
	// Create a copy of the program to avoid modifying the original
	enrichedProgram := *program

	// Build a map of types already in the program
	existingTypes := make(map[string]bool)
	for _, typeDef := range program.Types {
		existingTypes[typeDef.Name] = true
	}

	// Add types from the network that aren't already in the program
	for _, networkType := range network.Types {
		if !existingTypes[networkType.Name] {
			// Convert rete.TypeDefinition to constraint.TypeDefinition
			constraintType := constraint.TypeDefinition{
				Type:   networkType.Type,
				Name:   networkType.Name,
				Fields: make([]constraint.Field, len(networkType.Fields)),
			}

			// Convert fields
			for i, field := range networkType.Fields {
				constraintType.Fields[i] = constraint.Field{
					Name:         field.Name,
					Type:         field.Type,
					IsPrimaryKey: field.IsPrimaryKey,
				}
			}

			enrichedProgram.Types = append(enrichedProgram.Types, constraintType)
		}
	}

	return enrichedProgram
}

// executePipeline ex√©cute toutes les √©tapes du pipeline d'ingestion
func (cp *ConstraintPipeline) executePipeline(ctx *ingestionContext) error {
	// Phase 1: Pr√©paration
	if err := cp.prepareIngestion(ctx); err != nil {
		return err
	}

	// Phase 2: Construction r√©seau
	if err := cp.buildNetworkFromContext(ctx); err != nil {
		return err
	}

	// Phase 3: Gestion faits
	if err := cp.manageFacts(ctx); err != nil {
		return err
	}

	// Phase 4: Finalisation
	return cp.finalizeIngestion(ctx)
}

// prepareIngestion pr√©pare le contexte d'ingestion (parsing, reset, transaction, validation)
func (cp *ConstraintPipeline) prepareIngestion(ctx *ingestionContext) error {
	if err := cp.readAndParseFile(ctx); err != nil {
		return err
	}

	if err := cp.detectReset(ctx); err != nil {
		return err
	}

	if err := cp.initializeOrResetNetwork(ctx); err != nil {
		return err
	}

	if err := cp.beginTransactionIfNeeded(ctx); err != nil {
		return err
	}

	return cp.validateConstraints(ctx)
}

// buildNetworkFromContext construit ou √©tend le r√©seau RETE √† partir du contexte
func (cp *ConstraintPipeline) buildNetworkFromContext(ctx *ingestionContext) error {
	if err := cp.convertAndExtractComponents(ctx); err != nil {
		return err
	}

	if err := cp.extractXupleSpaces(ctx); err != nil {
		return err
	}

	if err := cp.createXupleSpaces(ctx); err != nil {
		return err
	}

	// Enregistrer l'action Xuple si un handler est configur√©
	if err := cp.registerXupleActionIfNeeded(ctx); err != nil {
		return err
	}

	return cp.addTypesAndRules(ctx)
}

// manageFacts g√®re la collection et la propagation des faits
func (cp *ConstraintPipeline) manageFacts(ctx *ingestionContext) error {
	if err := cp.collectExistingFactsIfNeeded(ctx); err != nil {
		return err
	}

	if err := cp.propagateToNewRules(ctx); err != nil {
		return err
	}

	return cp.submitNewFacts(ctx)
}

// finalizeIngestion finalise l'ingestion avec validation et commit
func (cp *ConstraintPipeline) finalizeIngestion(ctx *ingestionContext) error {
	if err := cp.validateNetworkAndState(ctx); err != nil {
		return err
	}

	return cp.verifyAndCommit(ctx)
}

// handlePipelineError g√®re les erreurs du pipeline avec rollback automatique
func (cp *ConstraintPipeline) handlePipelineError(ctx *ingestionContext, err error) (*ReteNetwork, *IngestionMetrics, error) {
	if ctx.tx != nil && ctx.tx.IsActive {
		rollbackErr := ctx.tx.Rollback()
		if rollbackErr != nil {
			cp.logger.Error("‚ùå Erreur rollback: %v", rollbackErr)
			return ctx.network, ctx.metrics.Finalize(), fmt.Errorf("erreur ingestion: %w; erreur rollback: %v", err, rollbackErr)
		}
		cp.logger.Warn("üîô Rollback automatique effectu√©")
	}
	return ctx.network, ctx.metrics.Finalize(), err
}

// readAndParseFile lit et parse le fichier de contraintes
func (cp *ConstraintPipeline) readAndParseFile(ctx *ingestionContext) error {
	parsingStart := time.Now()
	parsedAST, err := constraint.ParseConstraintFile(ctx.filename)
	if err != nil {
		ctx.metrics.RecordParsingDuration(time.Since(parsingStart))
		return fmt.Errorf("‚ùå Erreur parsing fichier %s: %w", ctx.filename, err)
	}
	ctx.parsedAST = parsedAST
	ctx.metrics.RecordParsingDuration(time.Since(parsingStart))
	cp.logger.Info("‚úÖ Parsing r√©ussi")
	return nil
}

// detectReset d√©tecte la pr√©sence d'une commande reset dans l'AST
func (cp *ConstraintPipeline) detectReset(ctx *ingestionContext) error {
	resultMap, ok := ctx.parsedAST.(map[string]interface{})
	if !ok {
		return fmt.Errorf("‚ùå Format AST non reconnu: %T", ctx.parsedAST)
	}

	if resetsData, exists := resultMap["resets"]; exists {
		if resets, ok := resetsData.([]interface{}); ok && len(resets) > 0 {
			ctx.hasResets = true
			cp.logger.Info("üîÑ Commande reset d√©tect√©e - R√©initialisation compl√®te du r√©seau")
		}
	}
	return nil
}

// initializeOrResetNetwork initialise ou r√©initialise le r√©seau selon le contexte
func (cp *ConstraintPipeline) initializeOrResetNetwork(ctx *ingestionContext) error {
	if ctx.hasResets {
		cp.logger.Info("üîÑ Commande reset d√©tect√©e - Garbage Collection de l'ancien r√©seau")

		if ctx.network != nil {
			cp.logger.Debug("üóëÔ∏è GC du r√©seau existant...")
			ctx.network.GarbageCollect()
			cp.logger.Debug("‚úÖ GC termin√©")
		}

		cp.logger.Info("üÜï Cr√©ation d'un nouveau r√©seau RETE")
		ctx.network = NewReteNetwork(ctx.storage)
		ctx.metrics.SetWasReset(true)
	}
	return nil
}

// beginTransactionIfNeeded d√©marre une transaction si le r√©seau existe
func (cp *ConstraintPipeline) beginTransactionIfNeeded(ctx *ingestionContext) error {
	if ctx.network != nil {
		ctx.tx = ctx.network.BeginTransaction()
		ctx.network.SetTransaction(ctx.tx)
		cp.logger.Info("üîí Transaction d√©marr√©e automatiquement: %s", ctx.tx.ID)
	}
	return nil
}

// validateConstraints effectue la validation s√©mantique
func (cp *ConstraintPipeline) validateConstraints(ctx *ingestionContext) error {
	validationStart := time.Now()
	if ctx.network == nil || ctx.hasResets {
		// Validation standard
		if err := constraint.ValidateConstraintProgram(ctx.parsedAST); err != nil {
			return fmt.Errorf("‚ùå Erreur validation s√©mantique: %w", err)
		}
		cp.logger.Info("‚úÖ Validation s√©mantique r√©ussie")
		ctx.metrics.SetValidationSkipped(false)
	} else {
		// Validation incr√©mentale
		cp.logger.Info("üîç Validation s√©mantique incr√©mentale avec contexte...")
		validator := NewIncrementalValidator(ctx.network)
		if err := validator.ValidateWithContext(ctx.parsedAST); err != nil {
			return fmt.Errorf("‚ùå Erreur validation incr√©mentale: %w", err)
		}
		cp.logger.Info("‚úÖ Validation incr√©mentale r√©ussie (%d types en contexte)", len(ctx.network.Types))
		ctx.metrics.SetValidationSkipped(false)
		ctx.metrics.SetWasIncremental(true)
	}
	ctx.metrics.RecordValidationDuration(time.Since(validationStart))
	return nil
}

// convertAndExtractComponents convertit l'AST en programme RETE et extrait les composants
func (cp *ConstraintPipeline) convertAndExtractComponents(ctx *ingestionContext) error {
	// Conversion en programme
	program, err := constraint.ConvertResultToProgram(ctx.parsedAST)
	if err != nil {
		return fmt.Errorf("‚ùå Erreur conversion programme: %w", err)
	}
	ctx.program = program

	// Cr√©er ou √©tendre le r√©seau
	if ctx.network == nil {
		cp.logger.Info("üÜï Cr√©ation d'un nouveau r√©seau RETE")
		ctx.network = NewReteNetwork(ctx.storage)
	} else if !ctx.hasResets {
		cp.logger.Info("üîÑ Extension du r√©seau RETE existant")
	}

	// Convertir au format RETE
	reteProgram, err := constraint.ConvertToReteProgram(program)
	if err != nil {
		return fmt.Errorf("‚ùå Erreur conversion programme RETE: %w", err)
	}
	ctx.reteProgram = reteProgram

	reteResultMap, ok := ctx.reteProgram.(map[string]interface{})
	if !ok {
		return fmt.Errorf("‚ùå Format programme RETE invalide: %T", ctx.reteProgram)
	}

	// Extraire les composants
	types, expressions, err := cp.extractComponents(reteResultMap)
	if err != nil {
		return fmt.Errorf("‚ùå Erreur extraction composants: %w", err)
	}
	ctx.types = types
	ctx.expressions = expressions
	cp.logger.Info("‚úÖ Trouv√© %d types et %d expressions dans le fichier", len(types), len(expressions))

	return nil
}

// addTypesAndRules ajoute les types et les r√®gles au r√©seau
func (cp *ConstraintPipeline) addTypesAndRules(ctx *ingestionContext) error {
	// Ajout types
	if len(ctx.types) > 0 {
		typeCreationStart := time.Now()
		if err := cp.createTypeNodes(ctx.network, ctx.types, ctx.storage); err != nil {
			return fmt.Errorf("‚ùå Erreur ajout types: %w", err)
		}
		cp.logger.Info("‚úÖ Types ajout√©s/mis √† jour dans le r√©seau")
		ctx.metrics.RecordTypeCreationDuration(time.Since(typeCreationStart))
		ctx.metrics.SetTypesAdded(len(ctx.types))
	}

	// Extraire et stocker les actions
	reteResultMap, _ := ctx.reteProgram.(map[string]interface{})
	if err := cp.extractAndStoreActions(ctx.network, reteResultMap); err != nil {
		return fmt.Errorf("‚ùå Erreur extraction actions: %w", err)
	}

	// Identifier terminaux existants
	ctx.existingTerminals = make(map[string]bool)
	for terminalID := range ctx.network.TerminalNodes {
		ctx.existingTerminals[terminalID] = true
	}

	// Ajouter les nouvelles r√®gles
	if len(ctx.expressions) > 0 {
		ruleCreationStart := time.Now()
		if err := cp.createRuleNodes(ctx.network, ctx.expressions, ctx.storage); err != nil {
			return fmt.Errorf("‚ùå Erreur ajout r√®gles: %w", err)
		}
		cp.logger.Info("‚úÖ R√®gles ajout√©es au r√©seau")
		ctx.metrics.RecordRuleCreationDuration(time.Since(ruleCreationStart))
		ctx.metrics.SetRulesAdded(len(ctx.expressions))
	}

	// Traiter les suppressions de r√®gles
	if err := cp.processRuleRemovals(ctx.network, reteResultMap); err != nil {
		return fmt.Errorf("‚ùå Erreur traitement suppressions de r√®gles: %w", err)
	}

	return nil
}

// collectExistingFactsIfNeeded collecte les faits existants si n√©cessaire
func (cp *ConstraintPipeline) collectExistingFactsIfNeeded(ctx *ingestionContext) error {
	if ctx.hasResets {
		cp.logger.Debug("üìä R√©seau r√©initialis√© - pas de faits pr√©existants")
	} else {
		collectionStart := time.Now()
		ctx.existingFacts = cp.collectExistingFacts(ctx.network)
		ctx.factsByType = cp.organizeFactsByType(ctx.existingFacts)
		cp.logger.Debug("üìä Faits pr√©existants dans le r√©seau: %d", len(ctx.existingFacts))
		ctx.metrics.RecordFactCollectionDuration(time.Since(collectionStart))
		ctx.metrics.SetExistingFactsCollected(len(ctx.existingFacts))
	}
	return nil
}

// propagateToNewRules propage les faits existants vers les nouvelles r√®gles
func (cp *ConstraintPipeline) propagateToNewRules(ctx *ingestionContext) error {
	ctx.newTerminals = cp.identifyNewTerminals(ctx.network, ctx.existingTerminals)
	if len(ctx.newTerminals) > 0 && len(ctx.existingFacts) > 0 {
		cp.logger.Info("üîÑ Propagation cibl√©e de faits vers %d nouvelle(s) r√®gle(s)", len(ctx.newTerminals))
		propagationStart := time.Now()
		propagatedCount := cp.propagateToNewTerminals(ctx.network, ctx.newTerminals, ctx.factsByType)
		ctx.metrics.RecordPropagationDuration(time.Since(propagationStart))
		ctx.metrics.SetFactsPropagated(propagatedCount)
		ctx.metrics.SetNewTerminalsAdded(len(ctx.newTerminals))
		ctx.metrics.SetPropagationTargets(len(ctx.newTerminals))
		cp.logger.Info("‚úÖ Propagation r√©troactive termin√©e (%d fait(s) propag√©(s))", propagatedCount)
	}
	return nil
}

// submitNewFacts soumet les nouveaux faits au r√©seau
func (cp *ConstraintPipeline) submitNewFacts(ctx *ingestionContext) error {
	if len(ctx.program.Facts) > 0 {
		// CRUCIAL: Merge network types into program for incremental validation
		// When loading facts from a separate file, the program only contains types
		// defined in that file. We need to merge in types from previous files.
		programWithAllTypes := cp.enrichProgramWithNetworkTypes(ctx.program, ctx.network)

		factsForRete, err := constraint.ConvertFactsToReteFormat(programWithAllTypes)
		if err != nil {
			return fmt.Errorf("‚ùå Erreur conversion faits: %w", err)
		}
		ctx.factsForRete = factsForRete
		cp.logger.Info("üì• Soumission de %d nouveaux faits", len(ctx.factsForRete))
		submissionStart := time.Now()
		if err := ctx.network.SubmitFactsFromGrammar(ctx.factsForRete); err != nil {
			return fmt.Errorf("‚ùå Erreur soumission faits: %w", err)
		}
		cp.logger.Info("‚úÖ Nouveaux faits soumis")
		ctx.metrics.RecordFactSubmissionDuration(time.Since(submissionStart))
		ctx.metrics.SetFactsSubmitted(len(ctx.factsForRete))
	}
	return nil
}

// validateNetworkAndState valide le r√©seau et enregistre son √©tat
func (cp *ConstraintPipeline) validateNetworkAndState(ctx *ingestionContext) error {
	if err := cp.validateNetwork(ctx.network); err != nil {
		return fmt.Errorf("‚ùå Erreur validation r√©seau: %w", err)
	}
	cp.logger.Info("‚úÖ Validation r√©ussie")

	// Enregistrer l'√©tat du r√©seau
	ctx.metrics.RecordNetworkState(ctx.network)
	cp.logger.Info("üéØ INGESTION INCR√âMENTALE TERMIN√âE")
	cp.logger.Info("   - Total TypeNodes: %d", len(ctx.network.TypeNodes))
	cp.logger.Info("   - Total TerminalNodes: %d", len(ctx.network.TerminalNodes))

	return nil
}

// extractXupleSpaces extrait les xuple-spaces depuis l'AST pars√©
func (cp *ConstraintPipeline) extractXupleSpaces(ctx *ingestionContext) error {
	resultMap, ok := ctx.parsedAST.(map[string]interface{})
	if !ok {
		return fmt.Errorf("format AST invalide pour extraction xuple-spaces")
	}

	xupleSpacesData, exists := resultMap["xupleSpaces"]
	if !exists {
		// Pas de xuple-spaces dans ce fichier, ce n'est pas une erreur
		return nil
	}

	xupleSpacesList, ok := xupleSpacesData.([]interface{})
	if !ok {
		return fmt.Errorf("format xupleSpaces invalide: %T", xupleSpacesData)
	}

	ctx.xupleSpaces = xupleSpacesList
	cp.logger.Info("‚úÖ Trouv√© %d xuple-space(s) √† cr√©er", len(xupleSpacesList))

	return nil
}

// createXupleSpaces stocke les d√©finitions de xuple-spaces d√©tect√©es lors du parsing.
// Les d√©finitions sont stock√©es dans le r√©seau et un callback optionnel est appel√©
// pour permettre au package api de cr√©er les xuple-spaces avant la soumission des faits inline.
//
// Note: La cr√©ation effective des xuple-spaces est g√©r√©e par le callback (package api),
// pas par ce pipeline. Le pipeline se contente de parser et stocker les d√©finitions.
func (cp *ConstraintPipeline) createXupleSpaces(ctx *ingestionContext) error {
	if len(ctx.xupleSpaces) == 0 {
		return nil
	}

	cp.logger.Info("‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ")
	cp.logger.Info("üì¶ D√âTECTION DES XUPLE-SPACES")
	cp.logger.Info("‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ")

	// Stocker les d√©finitions dans le r√©seau pour utilisation par le package api
	ctx.network.SetXupleSpaceDefinitions(ctx.xupleSpaces)
	cp.logger.Info("   %d xuple-space(s) d√©tect√©(s) et stock√©(s)", len(ctx.xupleSpaces))

	// Appeler le callback si configur√© (permet au package api de cr√©er les xuple-spaces imm√©diatement)
	if ctx.onXupleSpacesDetected != nil {
		cp.logger.Info("   Cr√©ation des xuple-spaces via callback...")
		if err := ctx.onXupleSpacesDetected(ctx.network, ctx.xupleSpaces); err != nil {
			return fmt.Errorf("erreur callback cr√©ation xuple-spaces: %w", err)
		}
		cp.logger.Info("   ‚úÖ Xuple-spaces cr√©√©s via callback")
	} else {
		cp.logger.Info("   Les xuple-spaces seront cr√©√©s automatiquement par le package api")
	}

	cp.logger.Info("")
	return nil
}

// registerXupleActionIfNeeded enregistre l'action Xuple si un handler est configur√©.
// Cette m√©thode est appel√©e apr√®s createXupleSpaces pour s'assurer que l'action
// est disponible m√™me si aucun xuple-space n'est d√©clar√© dans le fichier TSD.
//
// L'enregistrement est d√©sormais d√©l√©gu√© √† ActionExecutor.RegisterXupleActionIfNeeded()
// qui g√®re automatiquement la v√©rification et l'enregistrement.
func (cp *ConstraintPipeline) registerXupleActionIfNeeded(ctx *ingestionContext) error {
	// V√©rifier si un ActionExecutor est disponible
	if ctx.network == nil || ctx.network.ActionExecutor == nil {
		return nil
	}

	// D√©l√©guer l'enregistrement √† l'ActionExecutor
	if err := ctx.network.ActionExecutor.RegisterXupleActionIfNeeded(); err != nil {
		return fmt.Errorf("erreur enregistrement action Xuple: %w", err)
	}

	return nil
}

// verifyAndCommit v√©rifie la coh√©rence et commit la transaction
func (cp *ConstraintPipeline) verifyAndCommit(ctx *ingestionContext) error {
	// V√©rification de coh√©rence pr√©-commit
	if ctx.tx != nil && ctx.tx.IsActive && len(ctx.factsForRete) > 0 {
		cp.logger.Info("üîç V√©rification de coh√©rence pr√©-commit...")

		expectedFactCount := len(ctx.factsForRete)
		actualFactCount := 0
		missingFacts := make([]string, 0)

		for i, factMap := range ctx.factsForRete {
			// Utiliser _id_ qui contient d√©j√† le format Type~Value
			var internalID string
			if id, ok := factMap["_id_"].(string); ok {
				internalID = id
			} else {
				// Fallback: construire l'ID si _id_ n'existe pas
				var factID string
				if id, ok := factMap["id"].(string); ok {
					factID = id
				} else {
					factID = fmt.Sprintf("fact_%d", i)
				}

				factType := "unknown"
				if typ, ok := factMap["type"].(string); ok {
					factType = typ
				} else if typ, ok := factMap["reteType"].(string); ok {
					factType = typ
				}

				internalID = fmt.Sprintf("%s~%s", factType, factID)
			}

			if ctx.storage.GetFact(internalID) != nil {
				actualFactCount++
			} else {
				missingFacts = append(missingFacts, internalID)
			}
		}

		if expectedFactCount != actualFactCount {
			cp.logger.Error("‚ùå Incoh√©rence d√©tect√©e: %d faits attendus, %d trouv√©s", expectedFactCount, actualFactCount)
			cp.logger.Error("   Faits manquants: %v", missingFacts)
			return fmt.Errorf(
				"incoh√©rence pr√©-commit: %d faits attendus mais %d trouv√©s dans le storage",
				expectedFactCount, actualFactCount)
		}

		cp.logger.Info("‚úÖ Coh√©rence v√©rifi√©e: %d/%d faits pr√©sents", actualFactCount, expectedFactCount)

		// Synchroniser le storage
		cp.logger.Info("üíæ Synchronisation du storage...")
		if err := ctx.storage.Sync(); err != nil {
			return fmt.Errorf("‚ùå Erreur sync storage: %w", err)
		}
		cp.logger.Info("‚úÖ Storage synchronis√©")
	}

	// Commit transaction
	if ctx.tx != nil && ctx.tx.IsActive {
		if err := ctx.tx.Commit(); err != nil {
			return fmt.Errorf("‚ùå Erreur commit transaction: %w", err)
		}
		cp.logger.Info("‚úÖ Transaction committ√©e: %d changements", ctx.tx.GetCommandCount())
	}

	return nil
}
