// Copyright (c) 2025 TSD Contributors
// Licensed under the MIT License
// See LICENSE file in the project root for full license text

package rete

import (
	"fmt"
	"os"
	"time"

	"github.com/treivax/tsd/constraint"
)

// AggregationInfo contient les informations extraites d'une agr√©gation
type AggregationInfo struct {
	Function      string      // AVG, SUM, COUNT, MIN, MAX
	MainVariable  string      // Variable principale (ex: "e" pour Employee)
	MainType      string      // Type principal (ex: "Employee")
	AggVariable   string      // Variable √† agr√©ger (ex: "p" pour Performance)
	AggType       string      // Type √† agr√©ger (ex: "Performance")
	Field         string      // Champ √† agr√©ger (ex: "score")
	Operator      string      // Op√©rateur de comparaison (>=, >, etc.)
	Threshold     float64     // Valeur de seuil
	JoinField     string      // Champ de jointure dans faits agr√©g√©s (ex: "employee_id")
	MainField     string      // Champ de jointure dans fait principal (ex: "id")
	JoinCondition interface{} // Condition de jointure compl√®te

	// Multi-source aggregation support
	AggregationVars []AggregationVariable // Multiple aggregation variables
	SourcePatterns  []SourcePattern       // Multiple source patterns to join
	JoinConditions  []JoinCondition       // Join conditions between patterns
}

// AggregationVariable represents a single aggregation variable
type AggregationVariable struct {
	Name      string  // Variable name (ex: "avg_sal")
	Function  string  // AVG, SUM, COUNT, MIN, MAX
	SourceVar string  // Source variable (ex: "e")
	Field     string  // Field to aggregate (ex: "salary")
	Operator  string  // Threshold operator (>=, >, etc.)
	Threshold float64 // Threshold value
}

// SourcePattern represents a pattern block in multi-source aggregation
type SourcePattern struct {
	Variable string // Variable name (ex: "e")
	Type     string // Type name (ex: "Employee")
}

// ConstraintPipeline impl√©mente le pipeline complet :
// fichier .constraint ‚Üí parseur PEG ‚Üí conversion AST ‚Üí r√©seau RETE
type ConstraintPipeline struct {
	logger *Logger // Logger structur√© pour instrumentation
}

// GetLogger retourne le logger, en l'initialisant si n√©cessaire
func (cp *ConstraintPipeline) GetLogger() *Logger {
	if cp.logger == nil {
		cp.logger = NewLogger(LogLevelInfo, os.Stdout)
	}
	return cp.logger
}

// NewConstraintPipeline cr√©e une nouvelle instance du pipeline
func NewConstraintPipeline() *ConstraintPipeline {
	return &ConstraintPipeline{
		logger: NewLogger(LogLevelInfo, os.Stdout), // Logger par d√©faut niveau Info
	}
}

// SetLogger configure le logger pour le pipeline
func (cp *ConstraintPipeline) SetLogger(logger *Logger) {
	if logger != nil {
		cp.logger = logger
	}
}

// IngestFileWithMetrics est un wrapper qui collecte les m√©triques
// IngestFileWithMetrics ing√®re un fichier avec collecte de m√©triques
// IMPORTANT: Cette fonction utilise TOUJOURS les transactions avec auto-commit/auto-rollback.
// En cas d'erreur, la transaction est automatiquement annul√©e (rollback).
// En cas de succ√®s, la transaction est automatiquement valid√©e (commit).
func (cp *ConstraintPipeline) IngestFileWithMetrics(filename string, network *ReteNetwork, storage Storage) (*ReteNetwork, *IngestionMetrics, error) {
	metrics := NewMetricsCollector()
	resultNetwork, err := cp.ingestFileWithMetrics(filename, network, storage, metrics)
	finalMetrics := metrics.Finalize()
	return resultNetwork, finalMetrics, err
}

// IngestFile est la fonction unique et incr√©mentale pour √©tendre le r√©seau RETE.
// Elle peut √™tre appel√©e plusieurs fois avec des fichiers diff√©rents pour :
// - Parser le fichier (types, r√®gles, faits)
// - √âtendre le r√©seau RETE existant (ou cr√©er un nouveau r√©seau si network == nil)
// - Propager les faits pr√©existants vers les nouvelles r√®gles
// - Soumettre les nouveaux faits au r√©seau
//
// Cette fonction remplace toutes les anciennes variantes de pipeline.
// Le support de la commande 'reset' en milieu de fichier a √©t√© supprim√©.
//
// IMPORTANT: Cette fonction utilise TOUJOURS les transactions avec auto-commit/auto-rollback.
// En cas d'erreur, la transaction est automatiquement annul√©e (rollback).
// En cas de succ√®s, la transaction est automatiquement valid√©e (commit).
func (cp *ConstraintPipeline) IngestFile(filename string, network *ReteNetwork, storage Storage) (*ReteNetwork, error) {
	return cp.ingestFileWithMetrics(filename, network, storage, nil)
}

// ingestFileWithMetrics est l'impl√©mentation interne avec support optionnel des m√©triques
// IMPORTANT: G√®re les transactions automatiquement (TOUJOURS activ√©es)
func (cp *ConstraintPipeline) ingestFileWithMetrics(filename string, network *ReteNetwork, storage Storage, metrics *MetricsCollector) (*ReteNetwork, error) {
	cp.logger.Info("========================================")
	cp.logger.Info("üìÅ Ingestion incr√©mentale: %s", filename)

	// √âTAPE 1: Parsing du fichier
	parsingStart := time.Now()
	parsedAST, err := constraint.ParseConstraintFile(filename)
	if err != nil {
		return nil, fmt.Errorf("‚ùå Erreur parsing fichier %s: %w", filename, err)
	}
	if metrics != nil {
		metrics.RecordParsingDuration(time.Since(parsingStart))
	}
	cp.logger.Info("‚úÖ Parsing r√©ussi")

	// √âTAPE 2: V√©rifier la pr√©sence d'une commande reset
	resultMap, ok := parsedAST.(map[string]interface{})
	if !ok {
		return nil, fmt.Errorf("‚ùå Format AST non reconnu: %T", parsedAST)
	}

	hasResets := false
	if resetsData, exists := resultMap["resets"]; exists {
		if resets, ok := resetsData.([]interface{}); ok && len(resets) > 0 {
			hasResets = true
			cp.GetLogger().Info("üîÑ Commande reset d√©tect√©e - R√©initialisation compl√®te du r√©seau")
		}
	}

	// Si reset d√©tect√©, faire un GC de l'ancien r√©seau puis cr√©er un nouveau
	if hasResets {
		cp.GetLogger().Info("üîÑ Commande reset d√©tect√©e - Garbage Collection de l'ancien r√©seau")

		// OPTIMISATION 2: Garbage Collection automatique apr√®s reset
		if network != nil {
			cp.GetLogger().Debug("üóëÔ∏è GC du r√©seau existant...")
			network.GarbageCollect()
			cp.GetLogger().Debug("‚úÖ GC termin√©")
		}

		cp.GetLogger().Info("üÜï Cr√©ation d'un nouveau r√©seau RETE")
		network = NewReteNetwork(storage)
		if metrics != nil {
			metrics.SetWasReset(true)
		}
	}

	// √âTAPE 2.5: D√©marrer une transaction (OBLIGATOIRE) une fois que le r√©seau est d√©fini
	var tx *Transaction
	if network != nil {
		tx = network.BeginTransaction()
		network.SetTransaction(tx)
		cp.GetLogger().Info("üîí Transaction d√©marr√©e automatiquement: %s", tx.ID)
	}

	// Fonction de rollback en cas d'erreur
	rollbackOnError := func(err error) (*ReteNetwork, error) {
		if tx != nil && tx.IsActive {
			rollbackErr := tx.Rollback()
			if rollbackErr != nil {
				cp.GetLogger().Error("‚ùå Erreur rollback: %v", rollbackErr)
				return network, fmt.Errorf("erreur ingestion: %w; erreur rollback: %v", err, rollbackErr)
			}
			cp.GetLogger().Warn("üîô Rollback automatique effectu√©")
		}
		return network, err
	}

	// √âTAPE 3: Validation s√©mantique
	// OPTIMISATION 1: Validation incr√©mentale avec contexte (syst√©matiquement activ√©e)
	validationStart := time.Now()
	if network == nil || hasResets {
		// Validation standard pour la cr√©ation initiale ou apr√®s reset
		err = constraint.ValidateConstraintProgram(parsedAST)
		if err != nil {
			return rollbackOnError(fmt.Errorf("‚ùå Erreur validation s√©mantique: %w", err))
		}
		cp.GetLogger().Info("‚úÖ Validation s√©mantique r√©ussie")
		if metrics != nil {
			metrics.RecordValidationDuration(time.Since(validationStart))
			metrics.SetValidationSkipped(false)
		}
	} else {
		// Validation incr√©mentale avec contexte du r√©seau existant
		cp.GetLogger().Info("üîç Validation s√©mantique incr√©mentale avec contexte...")
		validator := NewIncrementalValidator(network)
		err = validator.ValidateWithContext(parsedAST)
		if err != nil {
			return rollbackOnError(fmt.Errorf("‚ùå Erreur validation incr√©mentale: %w", err))
		}
		cp.GetLogger().Info("‚úÖ Validation incr√©mentale r√©ussie (%d types en contexte)", len(network.Types))
		if metrics != nil {
			metrics.RecordValidationDuration(time.Since(validationStart))
			metrics.SetValidationSkipped(false)
			metrics.SetWasIncremental(true)
		}
	}

	// Convertir en programme
	program, err := constraint.ConvertResultToProgram(parsedAST)
	if err != nil {
		return nil, fmt.Errorf("‚ùå Erreur conversion programme: %w", err)
	}

	// √âTAPE 4: Cr√©er ou √©tendre le r√©seau
	if network == nil {
		cp.GetLogger().Info("üÜï Cr√©ation d'un nouveau r√©seau RETE")
		network = NewReteNetwork(storage)
	} else if !hasResets {
		cp.GetLogger().Info("üîÑ Extension du r√©seau RETE existant")
	}

	// Convertir au format RETE
	reteProgram := constraint.ConvertToReteProgram(program)
	reteResultMap, ok := reteProgram.(map[string]interface{})
	if !ok {
		return nil, fmt.Errorf("‚ùå Format programme RETE invalide: %T", reteProgram)
	}

	// √âTAPE 5: Extraire et ajouter les nouveaux types
	types, expressions, err := cp.extractComponents(reteResultMap)
	if err != nil {
		return nil, fmt.Errorf("‚ùå Erreur extraction composants: %w", err)
	}
	cp.GetLogger().Info("‚úÖ Trouv√© %d types et %d expressions dans le fichier", len(types), len(expressions))

	// Ajouter les types au r√©seau (√©vite les doublons automatiquement)
	typeCreationStart := time.Now()
	if len(types) > 0 {
		err = cp.createTypeNodes(network, types, storage)
		if err != nil {
			return nil, fmt.Errorf("‚ùå Erreur ajout types: %w", err)
		}
		cp.GetLogger().Info("‚úÖ Types ajout√©s/mis √† jour dans le r√©seau")
		if metrics != nil {
			metrics.RecordTypeCreationDuration(time.Since(typeCreationStart))
			metrics.SetTypesAdded(len(types))
		}
	}

	// √âTAPE 5.5: Extraire et stocker les d√©finitions d'actions
	err = cp.extractAndStoreActions(network, reteResultMap)
	if err != nil {
		return nil, fmt.Errorf("‚ùå Erreur extraction actions: %w", err)
	}

	// √âTAPE 6: Collecter tous les faits existants dans le r√©seau AVANT d'ajouter les nouvelles r√®gles
	// (sauf si reset car le r√©seau vient d'√™tre cr√©√© vide)
	var existingFacts []*Fact
	var existingFactsByType map[string][]*Fact
	collectionStart := time.Now()
	if !hasResets {
		existingFacts = cp.collectExistingFacts(network)
		existingFactsByType = cp.organizeFactsByType(existingFacts)
		cp.GetLogger().Debug("üìä Faits pr√©existants dans le r√©seau: %d", len(existingFacts))
		if metrics != nil {
			metrics.RecordFactCollectionDuration(time.Since(collectionStart))
			metrics.SetExistingFactsCollected(len(existingFacts))
		}
	} else {
		cp.GetLogger().Debug("üìä R√©seau r√©initialis√© - pas de faits pr√©existants")
	}

	// √âTAPE 7: Identifier les terminaux existants avant l'ajout de r√®gles
	existingTerminals := make(map[string]bool)
	for terminalID := range network.TerminalNodes {
		existingTerminals[terminalID] = true
	}

	// √âTAPE 8: Ajouter les nouvelles r√®gles
	ruleCreationStart := time.Now()
	if len(expressions) > 0 {
		err = cp.createRuleNodes(network, expressions, storage)
		if err != nil {
			return nil, fmt.Errorf("‚ùå Erreur ajout r√®gles: %w", err)
		}
		cp.GetLogger().Info("‚úÖ R√®gles ajout√©es au r√©seau")
		if metrics != nil {
			metrics.RecordRuleCreationDuration(time.Since(ruleCreationStart))
			metrics.SetRulesAdded(len(expressions))
		}
	}

	// √âTAPE 9: Traiter les suppressions de r√®gles (si pr√©sentes)
	err = cp.processRuleRemovals(network, reteResultMap)
	if err != nil {
		return nil, fmt.Errorf("‚ùå Erreur traitement suppressions de r√®gles: %w", err)
	}

	// √âTAPE 10: Propager les faits existants vers les nouvelles r√®gles uniquement
	newTerminals := cp.identifyNewTerminals(network, existingTerminals)

	if len(newTerminals) > 0 && len(existingFacts) > 0 {
		cp.GetLogger().Info("üîÑ Propagation cibl√©e de faits vers %d nouvelle(s) r√®gle(s)", len(newTerminals))

		// Propager de mani√®re cibl√©e pour chaque nouveau terminal
		propagationStart := time.Now()
		propagatedCount := cp.propagateToNewTerminals(network, newTerminals, existingFactsByType)

		if metrics != nil {
			metrics.RecordPropagationDuration(time.Since(propagationStart))
			metrics.SetFactsPropagated(propagatedCount)
			metrics.SetNewTerminalsAdded(len(newTerminals))
			metrics.SetPropagationTargets(len(newTerminals))
		}

		cp.GetLogger().Info("‚úÖ Propagation r√©troactive termin√©e (%d fait(s) propag√©(s))", propagatedCount)
	}

	// √âTAPE 10: Soumettre les nouveaux faits du fichier
	var factsForRete []map[string]interface{}
	if len(program.Facts) > 0 {
		factsForRete = constraint.ConvertFactsToReteFormat(*program)
		cp.GetLogger().Info("üì• Soumission de %d nouveaux faits", len(factsForRete))

		submissionStart := time.Now()
		err := network.SubmitFactsFromGrammar(factsForRete)
		if err != nil {
			return rollbackOnError(fmt.Errorf("‚ùå Erreur soumission faits: %w", err))
		}
		cp.GetLogger().Info("‚úÖ Nouveaux faits soumis")
		if metrics != nil {
			metrics.RecordFactSubmissionDuration(time.Since(submissionStart))
			metrics.SetFactsSubmitted(len(factsForRete))
		}
	}

	// √âTAPE 11: Validation finale
	err = cp.validateNetwork(network)
	if err != nil {
		return nil, fmt.Errorf("‚ùå Erreur validation r√©seau: %w", err)
	}
	cp.GetLogger().Info("‚úÖ Validation r√©ussie")

	// Enregistrer l'√©tat final du r√©seau dans les m√©triques
	if metrics != nil {
		metrics.RecordNetworkState(network)
	}

	cp.GetLogger().Info("üéØ INGESTION INCR√âMENTALE TERMIN√âE")
	cp.GetLogger().Info("   - Total TypeNodes: %d", len(network.TypeNodes))
	cp.GetLogger().Info("   - Total TerminalNodes: %d", len(network.TerminalNodes))

	// √âTAPE 12: V√©rification de coh√©rence avant commit
	if tx != nil && tx.IsActive && len(factsForRete) > 0 {
		cp.GetLogger().Info("üîç V√©rification de coh√©rence pr√©-commit...")

		// V√©rifier que tous les faits soumis sont bien dans le storage
		expectedFactCount := len(factsForRete)
		actualFactCount := 0
		missingFacts := make([]string, 0)

		for i, factMap := range factsForRete {
			var factID string
			if id, ok := factMap["id"].(string); ok {
				factID = id
			} else {
				// G√©n√©rer le m√™me ID que dans SubmitFactsFromGrammar
				factID = fmt.Sprintf("fact_%d", i)
			}

			// Extraire le type du fait
			factType := "unknown"
			if typ, ok := factMap["type"].(string); ok {
				factType = typ
			} else if typ, ok := factMap["reteType"].(string); ok {
				factType = typ
			}

			// Construire l'ID interne (Type_ID) comme dans GetInternalID()
			internalID := fmt.Sprintf("%s_%s", factType, factID)

			if storage.GetFact(internalID) != nil {
				actualFactCount++
			} else {
				missingFacts = append(missingFacts, internalID)
			}
		}

		if expectedFactCount != actualFactCount {
			cp.GetLogger().Error("‚ùå Incoh√©rence d√©tect√©e: %d faits attendus, %d trouv√©s", expectedFactCount, actualFactCount)
			cp.GetLogger().Error("   Faits manquants: %v", missingFacts)
			return rollbackOnError(fmt.Errorf(
				"incoh√©rence pr√©-commit: %d faits attendus mais %d trouv√©s dans le storage",
				expectedFactCount, actualFactCount))
		}

		cp.GetLogger().Info("‚úÖ Coh√©rence v√©rifi√©e: %d/%d faits pr√©sents", actualFactCount, expectedFactCount)

		// Synchroniser le storage pour garantir la durabilit√©
		cp.GetLogger().Info("üíæ Synchronisation du storage...")
		if err := storage.Sync(); err != nil {
			return rollbackOnError(fmt.Errorf("‚ùå Erreur sync storage: %w", err))
		}
		cp.GetLogger().Info("‚úÖ Storage synchronis√©")
	}

	// √âTAPE 13: Commit de la transaction (OBLIGATOIRE)
	if tx != nil && tx.IsActive {
		commitErr := tx.Commit()
		if commitErr != nil {
			return rollbackOnError(fmt.Errorf("‚ùå Erreur commit transaction: %w", commitErr))
		}
		cp.GetLogger().Info("‚úÖ Transaction committ√©e: %d changements", tx.GetCommandCount())
	}

	cp.GetLogger().Info("üéØ INGESTION TERMIN√âE")
	cp.GetLogger().Info("========================================")

	return network, nil
}

// collectExistingFacts parcourt tous les n≈ìuds du r√©seau pour collecter les faits existants
func (cp *ConstraintPipeline) collectExistingFacts(network *ReteNetwork) []*Fact {
	factMap := make(map[string]*Fact)

	// Collecter depuis le RootNode
	if network.RootNode != nil && network.RootNode.Memory != nil {
		for _, fact := range network.RootNode.Memory.Facts {
			if fact != nil {
				factMap[fact.ID] = fact
			}
		}
	}

	// Collecter depuis les TypeNodes
	for _, typeNode := range network.TypeNodes {
		for _, token := range typeNode.Memory.Tokens {
			for _, fact := range token.Facts {
				if fact != nil {
					factMap[fact.ID] = fact
				}
			}
		}
	}

	// Collecter depuis les AlphaNodes
	for _, alphaNode := range network.AlphaNodes {
		for _, token := range alphaNode.Memory.Tokens {
			for _, fact := range token.Facts {
				if fact != nil {
					factMap[fact.ID] = fact
				}
			}
		}
	}

	// Collecter depuis les BetaNodes (JoinNodes, ExistsNodes, AccumulatorNodes, etc.)
	for _, betaNodeInterface := range network.BetaNodes {
		// Essayer de caster en JoinNode
		if joinNode, ok := betaNodeInterface.(*JoinNode); ok {
			// M√©moire gauche
			for _, token := range joinNode.LeftMemory.Tokens {
				for _, fact := range token.Facts {
					if fact != nil {
						factMap[fact.ID] = fact
					}
				}
				// Collecter aussi les faits des parents dans les tokens de jointure
				for parent := token.Parent; parent != nil; parent = parent.Parent {
					for _, fact := range parent.Facts {
						if fact != nil {
							factMap[fact.ID] = fact
						}
					}
				}
			}
			// M√©moire droite
			for _, token := range joinNode.RightMemory.Tokens {
				for _, fact := range token.Facts {
					if fact != nil {
						factMap[fact.ID] = fact
					}
				}
			}
		}
		// Essayer de caster en ExistsNode
		if existsNode, ok := betaNodeInterface.(*ExistsNode); ok {
			for _, token := range existsNode.MainMemory.Tokens {
				for _, fact := range token.Facts {
					if fact != nil {
						factMap[fact.ID] = fact
					}
				}
			}
			for _, token := range existsNode.ExistsMemory.Tokens {
				for _, fact := range token.Facts {
					if fact != nil {
						factMap[fact.ID] = fact
					}
				}
			}
		}
		// Essayer de caster en AccumulatorNode
		if accNode, ok := betaNodeInterface.(*AccumulatorNode); ok {
			// Collecter depuis MainFacts
			for _, fact := range accNode.MainFacts {
				if fact != nil {
					factMap[fact.ID] = fact
				}
			}
			// Collecter depuis AllFacts
			for _, fact := range accNode.AllFacts {
				if fact != nil {
					factMap[fact.ID] = fact
				}
			}
		}
	}

	// Convertir la map en slice
	facts := make([]*Fact, 0, len(factMap))
	for _, fact := range factMap {
		facts = append(facts, fact)
	}

	return facts
}

// organizeFactsByType organise les faits par type pour une propagation cibl√©e
func (cp *ConstraintPipeline) organizeFactsByType(facts []*Fact) map[string][]*Fact {
	factsByType := make(map[string][]*Fact)
	for _, fact := range facts {
		if fact != nil {
			factsByType[fact.Type] = append(factsByType[fact.Type], fact)
		}
	}
	return factsByType
}

// identifyNewTerminals identifie les n≈ìuds terminaux qui viennent d'√™tre ajout√©s
func (cp *ConstraintPipeline) identifyNewTerminals(network *ReteNetwork, existingTerminals map[string]bool) []*TerminalNode {
	var newTerminals []*TerminalNode
	for terminalID, terminal := range network.TerminalNodes {
		if !existingTerminals[terminalID] {
			newTerminals = append(newTerminals, terminal)
		}
	}
	return newTerminals
}

// propagateToNewTerminals propage les faits existants uniquement vers les nouvelles cha√Ænes de r√®gles
func (cp *ConstraintPipeline) propagateToNewTerminals(
	network *ReteNetwork,
	newTerminals []*TerminalNode,
	factsByType map[string][]*Fact,
) int {
	propagatedCount := 0

	// Pour chaque nouveau terminal, identifier les types de faits qu'il attend
	for _, terminal := range newTerminals {
		// Identifier les types de faits attendus par cette r√®gle
		expectedTypes := cp.identifyExpectedTypesForTerminal(network, terminal)

		// Propager uniquement les faits des types attendus
		for _, typeName := range expectedTypes {
			if facts, exists := factsByType[typeName]; exists {
				for _, fact := range facts {
					// Propager le fait via le TypeNode correspondant
					if typeNode, exists := network.TypeNodes[typeName]; exists {
						// Cr√©er un token pour ce fait
						token := &Token{
							ID:     fmt.Sprintf("retro_%s_%s", typeName, fact.ID),
							NodeID: typeNode.GetID(),
							Facts:  []*Fact{fact},
						}

						// Propager aux enfants du TypeNode
						err := typeNode.PropagateToChildren(fact, token)
						if err == nil {
							propagatedCount++
						}
					}
				}
			}
		}
	}

	return propagatedCount
}

// identifyExpectedTypesForTerminal identifie les types de faits attendus par un terminal
func (cp *ConstraintPipeline) identifyExpectedTypesForTerminal(network *ReteNetwork, terminal *TerminalNode) []string {
	expectedTypes := make(map[string]bool)

	// Parcourir les TypeNodes pour trouver ceux qui ont ce terminal comme descendant
	for typeName, typeNode := range network.TypeNodes {
		if cp.isTerminalReachableFrom(typeNode, terminal.GetID()) {
			expectedTypes[typeName] = true
		}
	}

	// Convertir en slice
	types := make([]string, 0, len(expectedTypes))
	for typeName := range expectedTypes {
		types = append(types, typeName)
	}

	return types
}

// isTerminalReachableFrom v√©rifie si un terminal est accessible depuis un n≈ìud donn√©
func (cp *ConstraintPipeline) isTerminalReachableFrom(node Node, terminalID string) bool {
	// V√©rification directe
	if node.GetID() == terminalID {
		return true
	}

	// V√©rification r√©cursive dans les enfants
	for _, child := range node.GetChildren() {
		if cp.isTerminalReachableFrom(child, terminalID) {
			return true
		}
	}

	return false
}

// processRuleRemovals traite les commandes de suppression de r√®gles
func (cp *ConstraintPipeline) processRuleRemovals(network *ReteNetwork, resultMap map[string]interface{}) error {
	// V√©rifier si des suppressions de r√®gles sont pr√©sentes
	ruleRemovalsData, exists := resultMap["ruleRemovals"]
	if !exists {
		return nil // Pas de suppressions de r√®gles
	}

	ruleRemovals, ok := ruleRemovalsData.([]interface{})
	if !ok || len(ruleRemovals) == 0 {
		return nil // Pas de suppressions de r√®gles
	}

	cp.GetLogger().Info("üóëÔ∏è  Traitement de %d suppression(s) de r√®gles", len(ruleRemovals))

	// Traiter chaque suppression de r√®gle
	for _, removalData := range ruleRemovals {
		removalMap, ok := removalData.(map[string]interface{})
		if !ok {
			cp.GetLogger().Warn("‚ö†Ô∏è  Format de suppression invalide: %v", removalData)
			continue
		}

		ruleID, ok := removalMap["ruleID"].(string)
		if !ok || ruleID == "" {
			cp.GetLogger().Warn("‚ö†Ô∏è  Identifiant de r√®gle manquant ou invalide: %v", removalMap)
			continue
		}

		// Supprimer la r√®gle du r√©seau
		cp.GetLogger().Info("üóëÔ∏è  Suppression de la r√®gle: %s", ruleID)
		err := network.RemoveRule(ruleID)
		if err != nil {
			// Logger l'erreur mais continuer avec les autres suppressions
			cp.GetLogger().Warn("‚ö†Ô∏è  Erreur lors de la suppression de la r√®gle %s: %v", ruleID, err)
			continue
		}

		cp.GetLogger().Info("‚úÖ R√®gle %s supprim√©e avec succ√®s", ruleID)
	}

	return nil
}
